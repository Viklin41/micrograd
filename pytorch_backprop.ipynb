{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5100bbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "---\n",
      "x2 0.5000001283844369\n",
      "w2 0.0\n",
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0]).double()                       ; x1.requires_grad= True\n",
    "x2 = torch.Tensor([0.0]).double()                       ; x2.requires_grad= True\n",
    "w1 = torch.Tensor([-3.0]).double()                      ; w1.requires_grad= True\n",
    "w2 = torch.Tensor([1.0]).double()                       ; w2.requires_grad= True\n",
    "\n",
    "b = torch. Tensor ([6.8813735870195432]).double()       ; b.requires_grad= True\n",
    "n = x1*w1 + x2*w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "\n",
    "print('---')\n",
    "print('x2', x2.grad.item())\n",
    "print('w2', w2.grad.item())\n",
    "print('x1', x1.grad.item())\n",
    "print('w1', w1.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3261a55",
   "metadata": {},
   "source": [
    "**PyTorch** is an open-source **deep learning framework** developed by Meta (Facebook). It is widely used in both **research and industry** to build, train, and deploy **neural networks**. PyTorch is especially popular because it is **intuitive, flexible, and Pythonic**, making it easy to experiment with complex models.\n",
    "\n",
    "---\n",
    "\n",
    "## What PyTorch Is\n",
    "\n",
    "At its core, PyTorch provides:\n",
    "\n",
    "### 1. Tensors\n",
    "\n",
    "Tensors are multidimensional arrays, similar to NumPy arrays, but with two key advantages:\n",
    "\n",
    "* They can run on **GPUs** for fast computation\n",
    "* They support **automatic differentiation**\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Automatic Differentiation (Autograd)\n",
    "\n",
    "PyTorch automatically computes gradients for you using **reverse-mode differentiation**, which is essential for training neural networks via **backpropagation**.\n",
    "\n",
    "Mathematically, if a loss function is:\n",
    "$$L = f(\\theta)$$\n",
    "\n",
    "PyTorch computes:\n",
    "$$\\frac{\\partial L}{\\partial \\theta}$$\n",
    "automatically.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Dynamic Computational Graphs\n",
    "\n",
    "Unlike older frameworks (e.g. TensorFlow 1.x), PyTorch builds the computational graph **on the fly** as the code runs.\n",
    "This makes debugging easier and allows:\n",
    "\n",
    "* Conditional logic\n",
    "* Variable-length inputs\n",
    "* More natural Python control flow\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Neural Network Module (`torch.nn`)\n",
    "\n",
    "PyTorch provides high-level building blocks:\n",
    "\n",
    "* Layers (Linear, Conv2d, LSTM, etc.)\n",
    "* Activation functions (ReLU, Sigmoid, Softmax)\n",
    "* Loss functions (MSE, CrossEntropy)\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Neural Network Applications with PyTorch\n",
    "\n",
    "PyTorch is used across many domains. Below are the most important **neural network applications**.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Computer Vision\n",
    "\n",
    "Used for image and video understanding.\n",
    "\n",
    "**Typical models:**\n",
    "\n",
    "* Convolutional Neural Networks (CNNs)\n",
    "* ResNet, VGG, EfficientNet\n",
    "* Vision Transformers (ViT)\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* Image classification\n",
    "* Object detection\n",
    "* Face recognition\n",
    "* Medical imaging\n",
    "\n",
    "Example task:\n",
    "$$\\text{Image} \\rightarrow \\text{CNN} \\rightarrow \\text{Class Label}$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Natural Language Processing (NLP)\n",
    "\n",
    "PyTorch is the backbone of modern NLP libraries like **Hugging Face Transformers**.\n",
    "\n",
    "**Models:**\n",
    "\n",
    "* RNNs, LSTMs, GRUs\n",
    "* Transformers (BERT, GPT, T5)\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* Machine translation\n",
    "* Sentiment analysis\n",
    "* Text summarization\n",
    "* Chatbots and large language models\n",
    "\n",
    "Example:\n",
    "$$\\text{Text Tokens} \\rightarrow \\text{Transformer} \\rightarrow \\text{Meaning / Prediction}$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Time Series & Forecasting\n",
    "\n",
    "Used to model sequential data.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* Stock price prediction\n",
    "* Demand forecasting\n",
    "* Energy consumption\n",
    "* Macroeconomic indicators\n",
    "\n",
    "**Common architectures:**\n",
    "\n",
    "* LSTM\n",
    "* GRU\n",
    "* Temporal Convolutional Networks\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Recommendation Systems\n",
    "\n",
    "Neural networks learn userâ€“item interactions.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* Product recommendations\n",
    "* Content personalization\n",
    "* Advertising targeting\n",
    "\n",
    "Example:\n",
    "$$P(\\text{user likes item}) = \\sigma(\\mathbf{u}^\\top \\mathbf{i})$$\n",
    "\n",
    "PyTorch handles large-scale embeddings efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Reinforcement Learning\n",
    "\n",
    "PyTorch is heavily used in RL research.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* Game playing (AlphaZero-style agents)\n",
    "* Robotics\n",
    "* Autonomous systems\n",
    "* Algorithmic trading\n",
    "\n",
    "**Key idea:**\n",
    "$$\\pi(a|s) \\rightarrow \\max \\mathbb{E}[R]$$\n",
    "\n",
    "Libraries like **Stable-Baselines3** and **TorchRL** are built on PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Scientific & Economic Modeling\n",
    "\n",
    "Increasingly used in:\n",
    "\n",
    "* Causal inference\n",
    "* Agent-based models\n",
    "* Structural economic models\n",
    "* Behavioral modeling\n",
    "\n",
    "Neural networks approximate complex functions:\n",
    "$$y = f(x_1, x_2, \\dots, x_n)$$\n",
    "\n",
    "---\n",
    "\n",
    "## Why PyTorch Is So Popular\n",
    "\n",
    "* Easy to learn and read\n",
    "* Strong community and research support\n",
    "* Seamless GPU acceleration\n",
    "* Industry-ready deployment (TorchScript, ONNX)\n",
    "* Integrates well with Python data tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
